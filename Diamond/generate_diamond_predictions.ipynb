{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6411c44-f95f-49f7-8206-c1cf862f359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 生成Diamond工具的预测结果\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import deque, Counter\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "AAS = {'M': 18, 'F': 15, 'A': 3, 'P': 9, 'I': 12, 'D': 11, 'V': 6, 'K': 7, 'S': 2, 'N': 13, 'W': 20, 'T': 10, 'G': 4, 'L': 1, 'Y': 16, 'E': 5, 'H': 17, 'R': 8, 'Q': 14, 'C': 19}\n",
    "\n",
    "NAMESPACES = {\n",
    "    'cellular_component':'cc' ,\n",
    "    'molecular_function':'mf',\n",
    "    'biological_process':'bp'\n",
    "}\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093ae51e-cc41-48ad-a17e-3bcefdb8d4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "class Ontology(object):\n",
    "\n",
    "    def __init__(self, filename='data/go.obo', with_rels=False):\n",
    "        self.ont = self.load(filename, with_rels)\n",
    "        self.ic = None\n",
    "\n",
    "    def has_term(self, term_id):\n",
    "        return term_id in self.ont\n",
    "\n",
    "    def calculate_ic(self, annots):\n",
    "        cnt = Counter()\n",
    "        for x in annots:\n",
    "            cnt.update(x)\n",
    "        self.ic = {}\n",
    "        for go_id, n in cnt.items():\n",
    "            parents = self.get_parents(go_id)\n",
    "            if len(parents) == 0:\n",
    "                min_n = n\n",
    "            else:\n",
    "                min_n = min([cnt[x] for x in parents])\n",
    "            self.ic[go_id] = math.log(min_n / n, 2)\n",
    "    \n",
    "    def get_ic(self, go_id):\n",
    "        if self.ic is None:\n",
    "            raise Exception('Not yet calculated')\n",
    "        if go_id not in self.ic:\n",
    "            return 0.0\n",
    "        return self.ic[go_id]\n",
    "\n",
    "    def load(self, filename, with_rels):\n",
    "        ont = dict()\n",
    "        obj = None\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if line == '[Term]':\n",
    "                    if obj is not None:\n",
    "                        ont[obj['id']] = obj\n",
    "                    obj = dict()\n",
    "                    obj['is_a'] = list()\n",
    "                    obj['part_of'] = list()\n",
    "                    obj['regulates'] = list()\n",
    "                    obj['alt_ids'] = list()\n",
    "                    obj['is_obsolete'] = False\n",
    "                    continue\n",
    "                elif line == '[Typedef]':\n",
    "                    obj = None\n",
    "                else:\n",
    "                    if obj is None:\n",
    "                        continue\n",
    "                    l = line.split(\": \")\n",
    "                    if l[0] == 'id':\n",
    "                        obj['id'] = l[1]\n",
    "                    elif l[0] == 'alt_id':\n",
    "                        obj['alt_ids'].append(l[1])\n",
    "                    elif l[0] == 'namespace':\n",
    "                        obj['namespace'] = l[1]\n",
    "                    elif l[0] == 'is_a':\n",
    "                        obj['is_a'].append(l[1].split(' ! ')[0])\n",
    "                    elif with_rels and l[0] == 'relationship':\n",
    "                        it = l[1].split()\n",
    "                        if it[0] == 'part_of':\n",
    "                            obj['is_a'].append(it[1])\n",
    "                            \n",
    "                    elif l[0] == 'name':\n",
    "                        obj['name'] = l[1]\n",
    "                    elif l[0] == 'is_obsolete' and l[1] == 'true':\n",
    "                        obj['is_obsolete'] = True\n",
    "        if obj is not None:\n",
    "            ont[obj['id']] = obj\n",
    "        for term_id in list(ont.keys()):\n",
    "            for t_id in ont[term_id]['alt_ids']:\n",
    "                ont[t_id] = ont[term_id]\n",
    "            if ont[term_id]['is_obsolete']:\n",
    "                del ont[term_id]\n",
    "        for term_id, val in ont.items():\n",
    "            if 'children' not in val:\n",
    "                val['children'] = set()\n",
    "            for p_id in val['is_a']:\n",
    "                if p_id in ont:\n",
    "                    if 'children' not in ont[p_id]:\n",
    "                        ont[p_id]['children'] = set()\n",
    "                    ont[p_id]['children'].add(term_id)\n",
    "        return ont\n",
    "\n",
    "\n",
    "    def get_anchestors(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while(len(q) > 0):\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for parent_id in self.ont[t_id]['is_a']:\n",
    "                    if parent_id in self.ont:\n",
    "                        q.append(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_parents(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        for parent_id in self.ont[term_id]['is_a']:\n",
    "            if parent_id in self.ont:\n",
    "                term_set.add(parent_id)\n",
    "        return term_set\n",
    "\n",
    "\n",
    "    def get_namespace_terms(self, namespace):\n",
    "        terms = set()\n",
    "        for go_id, obj in self.ont.items():\n",
    "            if obj['namespace'] == namespace:\n",
    "                terms.add(go_id)\n",
    "        return terms\n",
    "\n",
    "    def get_namespace(self, term_id):\n",
    "        return self.ont[term_id]['namespace']\n",
    "    \n",
    "    def get_term_set(self, term_id):\n",
    "        if term_id not in self.ont:\n",
    "            return set()\n",
    "        term_set = set()\n",
    "        q = deque()\n",
    "        q.append(term_id)\n",
    "        while len(q) > 0:\n",
    "            t_id = q.popleft()\n",
    "            if t_id not in term_set:\n",
    "                term_set.add(t_id)\n",
    "                for ch_id in self.ont[t_id]['children']:\n",
    "                    q.append(ch_id)\n",
    "        return term_set\n",
    "    \n",
    "def read_pkl(input_file):\n",
    "    with open(input_file,'rb') as fr:\n",
    "        temp_result = pkl.load(fr)\n",
    "    \n",
    "    return temp_result\n",
    "\n",
    "def save_pkl(output_file,data):\n",
    "    with open(output_file,'wb') as fw:\n",
    "        pkl.dump(data,fw)\n",
    "        \n",
    "def get_label(anations,func_list):\n",
    "    temp_result = []\n",
    "    for label in func_list:\n",
    "        if label in anations:\n",
    "            temp_result.append(1)\n",
    "        else:\n",
    "            temp_result.append(0)\n",
    "    return np.array(temp_result)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d7dff0-f95c-4d04-b03e-27b9abfc3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/wbshi/work/swissprot_data/train_test_data_handled_v4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612e3705-4005-403b-9046-eda108ca03ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(base_path + 'train_data_separate.pkl', 'rb') as fr:\n",
    "    protein_message = pkl.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc4befc-025e-4d7f-999f-512af830c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70016\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(protein_message.keys()))  #ABCG1_HUMAN\n",
    "print('ABCG1_HUMAN' in protein_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6248b31-2011-4f0d-8c74-ac9499b678c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079 36\n",
      "****************************************************************************************************\n",
      "1118 25\n",
      "****************************************************************************************************\n",
      "61069 235\n"
     ]
    }
   ],
   "source": [
    "go = Ontology(base_path+'handled_protein_messages/go.obo', with_rels=True)\n",
    "\n",
    "def read_diamond_result(input_file):\n",
    "    diamond_result = {}\n",
    "    with open(input_file,'r') as f:\n",
    "        for line in f:\n",
    "            it = line.strip().split()\n",
    "            # protein_1 = it[0].split('|')[1]\n",
    "            # protein_2 = it[1].split('|')[1]\n",
    "            protein_1 = it[0]\n",
    "            protein_2 = it[1]\n",
    "            score = float(it[2])\n",
    "            \n",
    "            if protein_1 not in diamond_result:\n",
    "                diamond_result[protein_1] = {}\n",
    "            if protein_1 != protein_2:\n",
    "                diamond_result[protein_1][protein_2] = score\n",
    "    return diamond_result\n",
    "\n",
    "def gennerate_diamond_score(input_file,output_file):\n",
    "    \n",
    "    # protein_message = pd.read_pickle('train_data_2016.pkl').set_index('proteins')\n",
    "    \n",
    "    with open(base_path + 'train_data_separate.pkl', 'rb') as fr:\n",
    "        protein_message = pkl.load(fr)\n",
    "        \n",
    "    diamond_result = read_diamond_result(input_file)\n",
    "    \n",
    "    diamond_function_result = {}\n",
    "    \n",
    "    all_p_set = set()\n",
    "    for prot_id,sim_prots in diamond_result.items():\n",
    "        if len(sim_prots) == 0:\n",
    "            continue\n",
    "            \n",
    "#         annots = {}\n",
    "        allgos = {}\n",
    "        total_score = 0.0\n",
    "        for proteins, score in sim_prots.items():\n",
    "            if proteins not in protein_message:\n",
    "                # print(proteins)\n",
    "                all_p_set.add(proteins)\n",
    "                continue\n",
    "            \n",
    "            for i in list(protein_message[proteins]['all_bp'] | protein_message[proteins]['all_cc'] | protein_message[proteins]['all_mf']):\n",
    "                if i not in allgos:\n",
    "                    allgos[i] = score\n",
    "                else:\n",
    "                    allgos[i] += score\n",
    "\n",
    "            total_score += score\n",
    "        allgos_res = {}\n",
    "        for key,value in allgos.items():\n",
    "            allgos_res[key] = value / total_score\n",
    "            \n",
    "        diamond_function_result[prot_id] = allgos_res\n",
    "    \n",
    "    print(len(diamond_function_result), len(all_p_set))\n",
    "    save_pkl(output_file,diamond_function_result)\n",
    "            \n",
    "            \n",
    "input_path = './diamond_{0}_all_sequence.result'\n",
    "\n",
    "ouput_path = './'\n",
    "if not os.path.exists(ouput_path):\n",
    "    os.mkdir(ouput_path)\n",
    "\n",
    "ouput_path = ouput_path + 'diamond_oral_{0}_func_score.pkl'\n",
    "\n",
    "input_file = input_path.format('test_one')\n",
    "output_file = ouput_path.format('test_one')\n",
    "gennerate_diamond_score(input_file,output_file)\n",
    "print('*'*100)\n",
    "\n",
    "input_file = input_path.format('test_two')\n",
    "output_file = ouput_path.format('test_two')\n",
    "gennerate_diamond_score(input_file,output_file)\n",
    "print('*'*100)\n",
    "\n",
    "input_file = input_path.format('train')\n",
    "output_file = ouput_path.format('train')\n",
    "gennerate_diamond_score(input_file,output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab023a2-86b0-42d9-ae86-e3a68926df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1353\n",
      "1381\n"
     ]
    }
   ],
   "source": [
    "# go = Ontology('./data/20210101_go.obo', with_rels=True)\n",
    "go = Ontology(base_path+'handled_protein_messages/go.obo', with_rels=True)\n",
    "\n",
    "\n",
    "for types in ['test_one', 'test_two']:\n",
    "    all_result = {}\n",
    "    data_file = './diamond_oral_{0}_func_score.pkl'.format(types)\n",
    "    temp_result = read_pkl(data_file)\n",
    "\n",
    "    all_test_protein_id = set()\n",
    "\n",
    "    input_file = base_path + \"{0}_data_all_sequences.fasta\".format(types)\n",
    "    with open(input_file,'r') as fr:\n",
    "        for line in fr:\n",
    "            if line.startswith('>'):\n",
    "                # accsion,protein_id = line.strip().split('|')\n",
    "                protein_id = line.strip()[1:]\n",
    "                all_test_protein_id.add(protein_id)\n",
    "\n",
    "    for protein in all_test_protein_id:\n",
    "        all_result[protein] = {}\n",
    "        all_result[protein]['bp'] = {}\n",
    "        all_result[protein]['cc'] = {}\n",
    "        all_result[protein]['mf'] = {}\n",
    "        if protein not in temp_result:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        for func,score in temp_result[protein].items():\n",
    "            tag = NAMESPACES[go.get_namespace(func)]\n",
    "            all_result[protein][tag][func] = score\n",
    "            \n",
    "    print(len(all_result))\n",
    "    outPut_path = './diamond_final_{0}_predict_score.pkl'.format(types)\n",
    "    save_pkl(outPut_path,all_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepFRI",
   "language": "python",
   "name": "deepfri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
